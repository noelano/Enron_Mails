{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook will serve for initial exploratory analysis of the Enrom email dataset.\n",
    "We'll look at the volume of mails grouped by user and perform some basic text analysis of the contents to determine whether a distinction can be made between suspicious and general work mails.\n",
    "Note that the dataset contains the full mail folders of the selected users, so this includes both inboxes and sent_items. To avoid duplicating mails we'll just look at the sent_items for each user*. This will also make it clearer when creating the network as a directed graph.\n",
    "\n",
    "* This will require a bit of work - the folder names aren't standardised so there may not be a sent_mail folder for each user. In addition there are 2 users who do not have a folder containing the string 'sent'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import numpy as np\n",
    "from email.parser import Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load the mail contents into a dataframe using Eannas mail_analyzer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyse_email(inputfile, df):\n",
    "    with open(inputfile, \"r\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    email = Parser().parsestr(data)\n",
    "\n",
    "    if email['to']:\n",
    "        email_to = email['to']\n",
    "        email_to = email_to.replace(\"\\n\", \"\")\n",
    "        email_to = email_to.replace(\"\\t\", \"\")\n",
    "        email_to = email_to.replace(\" \", \"\")\n",
    "\n",
    "        email_to = email_to.split(\",\")\n",
    "\n",
    "        to_length = len(email_to)\n",
    "\n",
    "        from_col = [email['from']] * to_length\n",
    "    else: \n",
    "        from_col = [email['from']]\n",
    "        email_to = [\"\"]\n",
    "    \n",
    "    email_df = pd.DataFrame(np.column_stack([from_col, email_to]),\n",
    "                            columns = ['From', 'To'])\n",
    "    return(email_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootdir = \"AAIC_Fraud_Hackathon\\\\maildir\\\\\"\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        'From' : [],\n",
    "        'To' : []})\n",
    "\n",
    "all_frames = []\n",
    "for directory, subdirectory, filenames in os.walk(rootdir):\n",
    "    frames = [analyse_email(os.path.join(directory, filename), df) for filename in filenames]\n",
    "    all_frames.extend(frames)\n",
    "\n",
    "df = pd.concat(all_frames)\n",
    "\n",
    "df = df[df.To != \"\"]\n",
    "\n",
    "df.to_csv(\"Output\\\\emails_all.csv\",\n",
    "          index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### First simple graph\n",
    "As a starting point we'll build an initial graph using this dataset. First though, we'll want to group our existing dataset by From and To ie any mails between the same people will be counted - this count will be used then as the edge weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">'todd'.delahoussaye@enron.com</th>\n",
       "      <th>'todd'.delahoussaye@enron.com</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ajay.sharma@enron.com</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anne.bike@enron.com</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bianca.ornelas@enron.com</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brant.reves@enron.com</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Count\n",
       "From                          To                                  \n",
       "'todd'.delahoussaye@enron.com 'todd'.delahoussaye@enron.com      5\n",
       "                              ajay.sharma@enron.com              5\n",
       "                              anne.bike@enron.com                1\n",
       "                              bianca.ornelas@enron.com           5\n",
       "                              brant.reves@enron.com              5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate the dataset together - equivalent to a count(*) group by from and to\n",
    "df=pd.read_csv(\"Output\\\\emails_all.csv\")\n",
    "\n",
    "distinct_mails = pd.DataFrame(df.groupby(['From', 'To']).size(), columns=['Count'])\n",
    "\n",
    "distinct_mails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288695, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_mails.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By grouping records with the same from and to we've reduced the number of rows from almost 3 million to under 300,000. This number will be the amount of edges in our graph. Let's look at the distict count of senders / recievers to determine the number of vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"'todd'.delahoussaye@enron.com\", \"'todd'.delahoussaye@enron.com\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the edges in a seperate list\n",
    "edgeList = distinct_mails.index[:]\n",
    "\n",
    "edgeList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577390"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the list to combine all senders and recipients into a single list\n",
    "# Note that this step is slow...\n",
    "\n",
    "users = list(sum(edgeList, ()))\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71971"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Translating that to a set will give a unique list of users in our dataset\n",
    "users = list(set(users))\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our graph will have 71,971 vertices with 288695 edges. Lets build a first graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"'todd'.delahoussaye@enron.com\", \"'todd'.delahoussaye@enron.com\", 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll extract the contents of distinct_mails into a list of tuples\n",
    "weights = list(distinct_mails['Count'])\n",
    "edges = zip(edgeList, weights)\n",
    "edges = [(w[0][0], w[0][1], w[1]) for w in edges]\n",
    "\n",
    "edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_weighted_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71971"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288695"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brant.reves@enron.com',\n",
       " 'veronica.espinoza@enron.com',\n",
       " 'm..love@enron.com',\n",
       " 'wendi.lebrocq@enron.com',\n",
       " 'stewart.range@enron.com',\n",
       " 'sandy.olitsky@enron.com',\n",
       " 'luchas.johnson@enron.com',\n",
       " 'randy.bhatia@enron.com',\n",
       " 'reporting.exception@enron.com',\n",
       " 'c..gossett@enron.com',\n",
       " 'rudwell.johnson@enron.com',\n",
       " 'leslie.reeves@enron.com',\n",
       " 'anne.bike@enron.com',\n",
       " 'tanya.rohauer@enron.com',\n",
       " 'jeff.royed@enron.com',\n",
       " 'richard.deming@enron.com',\n",
       " 's..theriot@enron.com',\n",
       " 'patrick.mulvany@enron.com',\n",
       " 'jackson.logan@enron.com',\n",
       " 'michelle.nelson@enron.com',\n",
       " 'nick.moshou@enron.com',\n",
       " 'shifali.sharma@enron.com',\n",
       " 'nidia.mendoza@enron.com',\n",
       " 'susan.bailey@enron.com',\n",
       " 'keynan.dutton@enron.com',\n",
       " 'credit<.williams@enron.com>',\n",
       " 'bianca.ornelas@enron.com',\n",
       " 'm..scott@enron.com',\n",
       " 'lisa.hesse@enron.com',\n",
       " 'paul.radous@enron.com',\n",
       " 'd..sorenson@enron.com',\n",
       " 'errol.mclaughlin@enron.com',\n",
       " 'lesli.campbell@enron.com',\n",
       " 'derek.bailey@enron.com',\n",
       " 'laura.vargas@enron.com',\n",
       " 'ellen.wallumrod@enron.com',\n",
       " 'jean.bell@enron.com',\n",
       " \"'todd'.delahoussaye@enron.com\",\n",
       " 'ajay.sharma@enron.com',\n",
       " 'kam.keiser@enron.com']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at a particular user\n",
    "\n",
    "G.neighbors(\"'todd'.delahoussaye@enron.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
